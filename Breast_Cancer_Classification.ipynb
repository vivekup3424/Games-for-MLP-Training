{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets as dt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "tf.random.set_seed(3)\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer = dt.load_breast_cancer()\n",
    "df = pd.DataFrame(breast_cancer.data, columns = breast_cancer.feature_names)\n",
    "df['target'] = breast_cancer.target\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  target                   569 non-null    int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                0\n",
       "mean texture               0\n",
       "mean perimeter             0\n",
       "mean area                  0\n",
       "mean smoothness            0\n",
       "mean compactness           0\n",
       "mean concavity             0\n",
       "mean concave points        0\n",
       "mean symmetry              0\n",
       "mean fractal dimension     0\n",
       "radius error               0\n",
       "texture error              0\n",
       "perimeter error            0\n",
       "area error                 0\n",
       "smoothness error           0\n",
       "compactness error          0\n",
       "concavity error            0\n",
       "concave points error       0\n",
       "symmetry error             0\n",
       "fractal dimension error    0\n",
       "worst radius               0\n",
       "worst texture              0\n",
       "worst perimeter            0\n",
       "worst area                 0\n",
       "worst smoothness           0\n",
       "worst compactness          0\n",
       "worst concavity            0\n",
       "worst concave points       0\n",
       "worst symmetry             0\n",
       "worst fractal dimension    0\n",
       "target                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
       "count     569.000000              569.000000  ...     569.000000   \n",
       "mean        0.181162                0.062798  ...      25.677223   \n",
       "std         0.027414                0.007060  ...       6.146258   \n",
       "min         0.106000                0.049960  ...      12.020000   \n",
       "25%         0.161900                0.057700  ...      21.080000   \n",
       "50%         0.179200                0.061540  ...      25.410000   \n",
       "75%         0.195700                0.066120  ...      29.720000   \n",
       "max         0.304000                0.097440  ...      49.540000   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       worst fractal dimension      target  \n",
       "count               569.000000  569.000000  \n",
       "mean                  0.083946    0.627417  \n",
       "std                   0.018061    0.483918  \n",
       "min                   0.055040    0.000000  \n",
       "25%                   0.071460    0.000000  \n",
       "50%                   0.080040    1.000000  \n",
       "75%                   0.092080    1.000000  \n",
       "max                   0.207500    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    357\n",
       "0    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.462830</td>\n",
       "      <td>21.604906</td>\n",
       "      <td>115.365377</td>\n",
       "      <td>978.376415</td>\n",
       "      <td>0.102898</td>\n",
       "      <td>0.145188</td>\n",
       "      <td>0.160775</td>\n",
       "      <td>0.087990</td>\n",
       "      <td>0.192909</td>\n",
       "      <td>0.062680</td>\n",
       "      <td>...</td>\n",
       "      <td>21.134811</td>\n",
       "      <td>29.318208</td>\n",
       "      <td>141.370330</td>\n",
       "      <td>1422.286321</td>\n",
       "      <td>0.144845</td>\n",
       "      <td>0.374824</td>\n",
       "      <td>0.450606</td>\n",
       "      <td>0.182237</td>\n",
       "      <td>0.323468</td>\n",
       "      <td>0.091530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.146524</td>\n",
       "      <td>17.914762</td>\n",
       "      <td>78.075406</td>\n",
       "      <td>462.790196</td>\n",
       "      <td>0.092478</td>\n",
       "      <td>0.080085</td>\n",
       "      <td>0.046058</td>\n",
       "      <td>0.025717</td>\n",
       "      <td>0.174186</td>\n",
       "      <td>0.062867</td>\n",
       "      <td>...</td>\n",
       "      <td>13.379801</td>\n",
       "      <td>23.515070</td>\n",
       "      <td>87.005938</td>\n",
       "      <td>558.899440</td>\n",
       "      <td>0.124959</td>\n",
       "      <td>0.182673</td>\n",
       "      <td>0.166238</td>\n",
       "      <td>0.074444</td>\n",
       "      <td>0.270246</td>\n",
       "      <td>0.079442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean radius  mean texture  mean perimeter   mean area  \\\n",
       "target                                                          \n",
       "0         17.462830     21.604906      115.365377  978.376415   \n",
       "1         12.146524     17.914762       78.075406  462.790196   \n",
       "\n",
       "        mean smoothness  mean compactness  mean concavity  \\\n",
       "target                                                      \n",
       "0              0.102898          0.145188        0.160775   \n",
       "1              0.092478          0.080085        0.046058   \n",
       "\n",
       "        mean concave points  mean symmetry  mean fractal dimension  ...  \\\n",
       "target                                                              ...   \n",
       "0                  0.087990       0.192909                0.062680  ...   \n",
       "1                  0.025717       0.174186                0.062867  ...   \n",
       "\n",
       "        worst radius  worst texture  worst perimeter   worst area  \\\n",
       "target                                                              \n",
       "0          21.134811      29.318208       141.370330  1422.286321   \n",
       "1          13.379801      23.515070        87.005938   558.899440   \n",
       "\n",
       "        worst smoothness  worst compactness  worst concavity  \\\n",
       "target                                                         \n",
       "0               0.144845           0.374824         0.450606   \n",
       "1               0.124959           0.182673         0.166238   \n",
       "\n",
       "        worst concave points  worst symmetry  worst fractal dimension  \n",
       "target                                                                 \n",
       "0                   0.182237        0.323468                 0.091530  \n",
       "1                   0.074444        0.270246                 0.079442  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('target').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target', axis = 1)\n",
    "y = df['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_functions = ['relu', 'sigmoid', 'tanh']\n",
    "hidden_layers_range = [1, 2, 3]  # Number of hidden layers\n",
    "neurons_range = [10, 20, 30]     # Number of neurons in each hidden layer\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "epochs_range = [10, 20, 50]\n",
    "# Define parameter ranges\n",
    "input_shape = X_train_std.shape[1]\n",
    "performance_matrix = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu, Layers: 1, Neurons: 10, LR: 0.001, Epochs: 10\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.1343572735786438\n",
      "Activation: relu, Layers: 1, Neurons: 10, LR: 0.001, Epochs: 20\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.09794101864099503\n",
      "Activation: relu, Layers: 1, Neurons: 10, LR: 0.001, Epochs: 50\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 0.089063361287117\n",
      "Activation: relu, Layers: 1, Neurons: 10, LR: 0.01, Epochs: 10\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.0992157906293869\n",
      "Activation: relu, Layers: 1, Neurons: 10, LR: 0.01, Epochs: 20\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.14901351928710938\n",
      "Activation: relu, Layers: 1, Neurons: 10, LR: 0.01, Epochs: 50\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.1896609216928482\n",
      "Activation: relu, Layers: 1, Neurons: 10, LR: 0.1, Epochs: 10\n",
      "Test Accuracy: 0.9210526347160339, Test Loss: 0.34324148297309875\n",
      "Activation: relu, Layers: 1, Neurons: 10, LR: 0.1, Epochs: 20\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.4289991557598114\n",
      "Activation: relu, Layers: 1, Neurons: 10, LR: 0.1, Epochs: 50\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.3774740397930145\n",
      "Activation: relu, Layers: 1, Neurons: 20, LR: 0.001, Epochs: 10\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.12211917340755463\n",
      "Activation: relu, Layers: 1, Neurons: 20, LR: 0.001, Epochs: 20\n",
      "Test Accuracy: 0.9298245906829834, Test Loss: 0.14743097126483917\n",
      "Activation: relu, Layers: 1, Neurons: 20, LR: 0.001, Epochs: 50\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.0824960470199585\n",
      "Activation: relu, Layers: 1, Neurons: 20, LR: 0.01, Epochs: 10\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.15583418309688568\n",
      "Activation: relu, Layers: 1, Neurons: 20, LR: 0.01, Epochs: 20\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.1679975390434265\n",
      "Activation: relu, Layers: 1, Neurons: 20, LR: 0.01, Epochs: 50\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.24920037388801575\n",
      "Activation: relu, Layers: 1, Neurons: 20, LR: 0.1, Epochs: 10\n",
      "Test Accuracy: 0.9210526347160339, Test Loss: 0.3961981534957886\n",
      "Activation: relu, Layers: 1, Neurons: 20, LR: 0.1, Epochs: 20\n",
      "Test Accuracy: 0.9385964870452881, Test Loss: 0.5312098860740662\n",
      "Activation: relu, Layers: 1, Neurons: 20, LR: 0.1, Epochs: 50\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.34235242009162903\n",
      "Activation: relu, Layers: 1, Neurons: 30, LR: 0.001, Epochs: 10\n",
      "Test Accuracy: 0.9385964870452881, Test Loss: 0.12863720953464508\n",
      "Activation: relu, Layers: 1, Neurons: 30, LR: 0.001, Epochs: 20\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.09250760823488235\n",
      "Activation: relu, Layers: 1, Neurons: 30, LR: 0.001, Epochs: 50\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.0872134268283844\n",
      "Activation: relu, Layers: 1, Neurons: 30, LR: 0.01, Epochs: 10\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.12438138574361801\n",
      "Activation: relu, Layers: 1, Neurons: 30, LR: 0.01, Epochs: 20\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.1572732925415039\n",
      "Activation: relu, Layers: 1, Neurons: 30, LR: 0.01, Epochs: 50\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.22978132963180542\n",
      "Activation: relu, Layers: 1, Neurons: 30, LR: 0.1, Epochs: 10\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 0.2538740336894989\n",
      "Activation: relu, Layers: 1, Neurons: 30, LR: 0.1, Epochs: 20\n",
      "Test Accuracy: 0.9385964870452881, Test Loss: 0.5156865119934082\n",
      "Activation: relu, Layers: 1, Neurons: 30, LR: 0.1, Epochs: 50\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 1.309872031211853\n",
      "Activation: relu, Layers: 2, Neurons: 10, LR: 0.001, Epochs: 10\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 0.1934419423341751\n",
      "Activation: relu, Layers: 2, Neurons: 10, LR: 0.001, Epochs: 20\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 0.12407761067152023\n",
      "Activation: relu, Layers: 2, Neurons: 10, LR: 0.001, Epochs: 50\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.09085725247859955\n",
      "Activation: relu, Layers: 2, Neurons: 10, LR: 0.01, Epochs: 10\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.10681386291980743\n",
      "Activation: relu, Layers: 2, Neurons: 10, LR: 0.01, Epochs: 20\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.17082886397838593\n",
      "Activation: relu, Layers: 2, Neurons: 10, LR: 0.01, Epochs: 50\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 0.25750523805618286\n",
      "Activation: relu, Layers: 2, Neurons: 10, LR: 0.1, Epochs: 10\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.13382208347320557\n",
      "Activation: relu, Layers: 2, Neurons: 10, LR: 0.1, Epochs: 20\n",
      "Test Accuracy: 0.9298245906829834, Test Loss: 0.19177420437335968\n",
      "Activation: relu, Layers: 2, Neurons: 10, LR: 0.1, Epochs: 50\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 0.3684428632259369\n",
      "Activation: relu, Layers: 2, Neurons: 20, LR: 0.001, Epochs: 10\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.11225096136331558\n",
      "Activation: relu, Layers: 2, Neurons: 20, LR: 0.001, Epochs: 20\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.0996597558259964\n",
      "Activation: relu, Layers: 2, Neurons: 20, LR: 0.001, Epochs: 50\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.10910627990961075\n",
      "Activation: relu, Layers: 2, Neurons: 20, LR: 0.01, Epochs: 10\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.18494977056980133\n",
      "Activation: relu, Layers: 2, Neurons: 20, LR: 0.01, Epochs: 20\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.26201605796813965\n",
      "Activation: relu, Layers: 2, Neurons: 20, LR: 0.01, Epochs: 50\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 0.3966875672340393\n",
      "Activation: relu, Layers: 2, Neurons: 20, LR: 0.1, Epochs: 10\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.24732689559459686\n",
      "Activation: relu, Layers: 2, Neurons: 20, LR: 0.1, Epochs: 20\n",
      "Test Accuracy: 0.9385964870452881, Test Loss: 0.8726345300674438\n",
      "Activation: relu, Layers: 2, Neurons: 20, LR: 0.1, Epochs: 50\n",
      "Test Accuracy: 0.9385964870452881, Test Loss: 0.35898497700691223\n",
      "Activation: relu, Layers: 2, Neurons: 30, LR: 0.001, Epochs: 10\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.07566456496715546\n",
      "Activation: relu, Layers: 2, Neurons: 30, LR: 0.001, Epochs: 20\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.10199020802974701\n",
      "Activation: relu, Layers: 2, Neurons: 30, LR: 0.001, Epochs: 50\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.1397141069173813\n",
      "Activation: relu, Layers: 2, Neurons: 30, LR: 0.01, Epochs: 10\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.2494644671678543\n",
      "Activation: relu, Layers: 2, Neurons: 30, LR: 0.01, Epochs: 20\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.2732813060283661\n",
      "Activation: relu, Layers: 2, Neurons: 30, LR: 0.01, Epochs: 50\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 0.4852927625179291\n",
      "Activation: relu, Layers: 2, Neurons: 30, LR: 0.1, Epochs: 10\n",
      "Test Accuracy: 0.9385964870452881, Test Loss: 0.15062487125396729\n",
      "Activation: relu, Layers: 2, Neurons: 30, LR: 0.1, Epochs: 20\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.4278956651687622\n",
      "Activation: relu, Layers: 2, Neurons: 30, LR: 0.1, Epochs: 50\n",
      "Test Accuracy: 0.9298245906829834, Test Loss: 0.8676859140396118\n",
      "Activation: relu, Layers: 3, Neurons: 10, LR: 0.001, Epochs: 10\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 0.22812649607658386\n",
      "Activation: relu, Layers: 3, Neurons: 10, LR: 0.001, Epochs: 20\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.11787250638008118\n",
      "Activation: relu, Layers: 3, Neurons: 10, LR: 0.001, Epochs: 50\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 0.17344693839550018\n",
      "Activation: relu, Layers: 3, Neurons: 10, LR: 0.01, Epochs: 10\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.1851608157157898\n",
      "Activation: relu, Layers: 3, Neurons: 10, LR: 0.01, Epochs: 20\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.2913614511489868\n",
      "Activation: relu, Layers: 3, Neurons: 10, LR: 0.01, Epochs: 50\n",
      "Test Accuracy: 0.9385964870452881, Test Loss: 0.4892161190509796\n",
      "Activation: relu, Layers: 3, Neurons: 10, LR: 0.1, Epochs: 10\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.16313593089580536\n",
      "Activation: relu, Layers: 3, Neurons: 10, LR: 0.1, Epochs: 20\n",
      "Test Accuracy: 0.9298245906829834, Test Loss: 0.22581465542316437\n",
      "Activation: relu, Layers: 3, Neurons: 10, LR: 0.1, Epochs: 50\n",
      "Test Accuracy: 0.9298245906829834, Test Loss: 5.126681327819824\n",
      "Activation: relu, Layers: 3, Neurons: 20, LR: 0.001, Epochs: 10\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.09400589764118195\n",
      "Activation: relu, Layers: 3, Neurons: 20, LR: 0.001, Epochs: 20\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.16699892282485962\n",
      "Activation: relu, Layers: 3, Neurons: 20, LR: 0.001, Epochs: 50\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.12894634902477264\n",
      "Activation: relu, Layers: 3, Neurons: 20, LR: 0.01, Epochs: 10\n",
      "Test Accuracy: 0.9298245906829834, Test Loss: 0.22031958401203156\n",
      "Activation: relu, Layers: 3, Neurons: 20, LR: 0.01, Epochs: 20\n",
      "Test Accuracy: 0.9385964870452881, Test Loss: 0.34032467007637024\n",
      "Activation: relu, Layers: 3, Neurons: 20, LR: 0.01, Epochs: 50\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 0.5536418557167053\n",
      "Activation: relu, Layers: 3, Neurons: 20, LR: 0.1, Epochs: 10\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.36173421144485474\n",
      "Activation: relu, Layers: 3, Neurons: 20, LR: 0.1, Epochs: 20\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.3579367399215698\n",
      "Activation: relu, Layers: 3, Neurons: 20, LR: 0.1, Epochs: 50\n",
      "Test Accuracy: 0.9210526347160339, Test Loss: 5.147451877593994\n",
      "Activation: relu, Layers: 3, Neurons: 30, LR: 0.001, Epochs: 10\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.10208389163017273\n",
      "Activation: relu, Layers: 3, Neurons: 30, LR: 0.001, Epochs: 20\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 0.12153986096382141\n",
      "Activation: relu, Layers: 3, Neurons: 30, LR: 0.001, Epochs: 50\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.24074913561344147\n",
      "Activation: relu, Layers: 3, Neurons: 30, LR: 0.01, Epochs: 10\n",
      "Test Accuracy: 0.9298245906829834, Test Loss: 0.2991921305656433\n",
      "Activation: relu, Layers: 3, Neurons: 30, LR: 0.01, Epochs: 20\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.319383442401886\n",
      "Activation: relu, Layers: 3, Neurons: 30, LR: 0.01, Epochs: 50\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 0.4226774573326111\n",
      "Activation: relu, Layers: 3, Neurons: 30, LR: 0.1, Epochs: 10\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 1.3409839868545532\n",
      "Activation: relu, Layers: 3, Neurons: 30, LR: 0.1, Epochs: 20\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 0.49993619322776794\n",
      "Activation: relu, Layers: 3, Neurons: 30, LR: 0.1, Epochs: 50\n",
      "Test Accuracy: 0.9385964870452881, Test Loss: 0.8041276335716248\n",
      "Activation: sigmoid, Layers: 1, Neurons: 10, LR: 0.001, Epochs: 10\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 0.27981317043304443\n",
      "Activation: sigmoid, Layers: 1, Neurons: 10, LR: 0.001, Epochs: 20\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.15961489081382751\n",
      "Activation: sigmoid, Layers: 1, Neurons: 10, LR: 0.001, Epochs: 50\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.08692147582769394\n",
      "Activation: sigmoid, Layers: 1, Neurons: 10, LR: 0.01, Epochs: 10\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.08729521930217743\n",
      "Activation: sigmoid, Layers: 1, Neurons: 10, LR: 0.01, Epochs: 20\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.08700723201036453\n",
      "Activation: sigmoid, Layers: 1, Neurons: 10, LR: 0.01, Epochs: 50\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.1276559829711914\n",
      "Activation: sigmoid, Layers: 1, Neurons: 10, LR: 0.1, Epochs: 10\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.11376812309026718\n",
      "Activation: sigmoid, Layers: 1, Neurons: 10, LR: 0.1, Epochs: 20\n",
      "Test Accuracy: 0.9298245906829834, Test Loss: 0.24547061324119568\n",
      "Activation: sigmoid, Layers: 1, Neurons: 10, LR: 0.1, Epochs: 50\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 0.19775693118572235\n",
      "Activation: sigmoid, Layers: 1, Neurons: 20, LR: 0.001, Epochs: 10\n",
      "Test Accuracy: 0.9385964870452881, Test Loss: 0.22105853259563446\n",
      "Activation: sigmoid, Layers: 1, Neurons: 20, LR: 0.001, Epochs: 20\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.12410625070333481\n",
      "Activation: sigmoid, Layers: 1, Neurons: 20, LR: 0.001, Epochs: 50\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.08444914221763611\n",
      "Activation: sigmoid, Layers: 1, Neurons: 20, LR: 0.01, Epochs: 10\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.0841662734746933\n",
      "Activation: sigmoid, Layers: 1, Neurons: 20, LR: 0.01, Epochs: 20\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.10127478837966919\n",
      "Activation: sigmoid, Layers: 1, Neurons: 20, LR: 0.01, Epochs: 50\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.1088985949754715\n",
      "Activation: sigmoid, Layers: 1, Neurons: 20, LR: 0.1, Epochs: 10\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.15354982018470764\n",
      "Activation: sigmoid, Layers: 1, Neurons: 20, LR: 0.1, Epochs: 20\n",
      "Test Accuracy: 0.9824561476707458, Test Loss: 0.1448952555656433\n",
      "Activation: sigmoid, Layers: 1, Neurons: 20, LR: 0.1, Epochs: 50\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 0.22965240478515625\n",
      "Activation: sigmoid, Layers: 1, Neurons: 30, LR: 0.001, Epochs: 10\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.17139364778995514\n",
      "Activation: sigmoid, Layers: 1, Neurons: 30, LR: 0.001, Epochs: 20\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.10446523129940033\n",
      "Activation: sigmoid, Layers: 1, Neurons: 30, LR: 0.001, Epochs: 50\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.08085837960243225\n",
      "Activation: sigmoid, Layers: 1, Neurons: 30, LR: 0.01, Epochs: 10\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.08912864327430725\n",
      "Activation: sigmoid, Layers: 1, Neurons: 30, LR: 0.01, Epochs: 20\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.12513379752635956\n",
      "Activation: sigmoid, Layers: 1, Neurons: 30, LR: 0.01, Epochs: 50\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.1346430629491806\n",
      "Activation: sigmoid, Layers: 1, Neurons: 30, LR: 0.1, Epochs: 10\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.11587619036436081\n",
      "Activation: sigmoid, Layers: 1, Neurons: 30, LR: 0.1, Epochs: 20\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.1632506251335144\n",
      "Activation: sigmoid, Layers: 1, Neurons: 30, LR: 0.1, Epochs: 50\n",
      "Test Accuracy: 0.9385964870452881, Test Loss: 0.2668607831001282\n",
      "Activation: sigmoid, Layers: 2, Neurons: 10, LR: 0.001, Epochs: 10\n",
      "Test Accuracy: 0.7894737124443054, Test Loss: 0.5090270638465881\n",
      "Activation: sigmoid, Layers: 2, Neurons: 10, LR: 0.001, Epochs: 20\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.26203909516334534\n",
      "Activation: sigmoid, Layers: 2, Neurons: 10, LR: 0.001, Epochs: 50\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.10546182841062546\n",
      "Activation: sigmoid, Layers: 2, Neurons: 10, LR: 0.01, Epochs: 10\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.10285883396863937\n",
      "Activation: sigmoid, Layers: 2, Neurons: 10, LR: 0.01, Epochs: 20\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.09675659239292145\n",
      "Activation: sigmoid, Layers: 2, Neurons: 10, LR: 0.01, Epochs: 50\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.173451229929924\n",
      "Activation: sigmoid, Layers: 2, Neurons: 10, LR: 0.1, Epochs: 10\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.18057726323604584\n",
      "Activation: sigmoid, Layers: 2, Neurons: 10, LR: 0.1, Epochs: 20\n",
      "Test Accuracy: 0.9122806787490845, Test Loss: 0.39761286973953247\n",
      "Activation: sigmoid, Layers: 2, Neurons: 10, LR: 0.1, Epochs: 50\n",
      "Test Accuracy: 0.9298245906829834, Test Loss: 0.2586284577846527\n",
      "Activation: sigmoid, Layers: 2, Neurons: 20, LR: 0.001, Epochs: 10\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 0.35250890254974365\n",
      "Activation: sigmoid, Layers: 2, Neurons: 20, LR: 0.001, Epochs: 20\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.11810093373060226\n",
      "Activation: sigmoid, Layers: 2, Neurons: 20, LR: 0.001, Epochs: 50\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.07971372455358505\n",
      "Activation: sigmoid, Layers: 2, Neurons: 20, LR: 0.01, Epochs: 10\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.09464390575885773\n",
      "Activation: sigmoid, Layers: 2, Neurons: 20, LR: 0.01, Epochs: 20\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.09662683308124542\n",
      "Activation: sigmoid, Layers: 2, Neurons: 20, LR: 0.01, Epochs: 50\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.19717298448085785\n",
      "Activation: sigmoid, Layers: 2, Neurons: 20, LR: 0.1, Epochs: 10\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.10254083573818207\n",
      "Activation: sigmoid, Layers: 2, Neurons: 20, LR: 0.1, Epochs: 20\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.15273426473140717\n",
      "Activation: sigmoid, Layers: 2, Neurons: 20, LR: 0.1, Epochs: 50\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.17543178796768188\n",
      "Activation: sigmoid, Layers: 2, Neurons: 30, LR: 0.001, Epochs: 10\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 0.20434504747390747\n",
      "Activation: sigmoid, Layers: 2, Neurons: 30, LR: 0.001, Epochs: 20\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.09334816783666611\n",
      "Activation: sigmoid, Layers: 2, Neurons: 30, LR: 0.001, Epochs: 50\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.08641333132982254\n",
      "Activation: sigmoid, Layers: 2, Neurons: 30, LR: 0.01, Epochs: 10\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.10334686934947968\n",
      "Activation: sigmoid, Layers: 2, Neurons: 30, LR: 0.01, Epochs: 20\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.10277541726827621\n",
      "Activation: sigmoid, Layers: 2, Neurons: 30, LR: 0.01, Epochs: 50\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.2266625165939331\n",
      "Activation: sigmoid, Layers: 2, Neurons: 30, LR: 0.1, Epochs: 10\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.1388058364391327\n",
      "Activation: sigmoid, Layers: 2, Neurons: 30, LR: 0.1, Epochs: 20\n",
      "Test Accuracy: 0.9298245906829834, Test Loss: 0.36472582817077637\n",
      "Activation: sigmoid, Layers: 2, Neurons: 30, LR: 0.1, Epochs: 50\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.23675435781478882\n",
      "Activation: sigmoid, Layers: 3, Neurons: 10, LR: 0.001, Epochs: 10\n",
      "Test Accuracy: 0.6052631735801697, Test Loss: 0.5823025107383728\n",
      "Activation: sigmoid, Layers: 3, Neurons: 10, LR: 0.001, Epochs: 20\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.3499450087547302\n",
      "Activation: sigmoid, Layers: 3, Neurons: 10, LR: 0.001, Epochs: 50\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.11662556231021881\n",
      "Activation: sigmoid, Layers: 3, Neurons: 10, LR: 0.01, Epochs: 10\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.10775724053382874\n",
      "Activation: sigmoid, Layers: 3, Neurons: 10, LR: 0.01, Epochs: 20\n",
      "Test Accuracy: 0.9824561476707458, Test Loss: 0.08656690269708633\n",
      "Activation: sigmoid, Layers: 3, Neurons: 10, LR: 0.01, Epochs: 50\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.20206011831760406\n",
      "Activation: sigmoid, Layers: 3, Neurons: 10, LR: 0.1, Epochs: 10\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.07302606105804443\n",
      "Activation: sigmoid, Layers: 3, Neurons: 10, LR: 0.1, Epochs: 20\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.1715175360441208\n",
      "Activation: sigmoid, Layers: 3, Neurons: 10, LR: 0.1, Epochs: 50\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.15077973902225494\n",
      "Activation: sigmoid, Layers: 3, Neurons: 20, LR: 0.001, Epochs: 10\n",
      "Test Accuracy: 0.9473684430122375, Test Loss: 0.28607454895973206\n",
      "Activation: sigmoid, Layers: 3, Neurons: 20, LR: 0.001, Epochs: 20\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.11536353826522827\n",
      "Activation: sigmoid, Layers: 3, Neurons: 20, LR: 0.001, Epochs: 50\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.09375591576099396\n",
      "Activation: sigmoid, Layers: 3, Neurons: 20, LR: 0.01, Epochs: 10\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.10237382352352142\n",
      "Activation: sigmoid, Layers: 3, Neurons: 20, LR: 0.01, Epochs: 20\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.12508317828178406\n",
      "Activation: sigmoid, Layers: 3, Neurons: 20, LR: 0.01, Epochs: 50\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.15846620500087738\n",
      "Activation: sigmoid, Layers: 3, Neurons: 20, LR: 0.1, Epochs: 10\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.13397514820098877\n",
      "Activation: sigmoid, Layers: 3, Neurons: 20, LR: 0.1, Epochs: 20\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.1562984138727188\n",
      "Activation: sigmoid, Layers: 3, Neurons: 20, LR: 0.1, Epochs: 50\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.15115775167942047\n",
      "Activation: sigmoid, Layers: 3, Neurons: 30, LR: 0.001, Epochs: 10\n",
      "Test Accuracy: 0.9385964870452881, Test Loss: 0.332164466381073\n",
      "Activation: sigmoid, Layers: 3, Neurons: 30, LR: 0.001, Epochs: 20\n",
      "Test Accuracy: 0.9561403393745422, Test Loss: 0.0954575389623642\n",
      "Activation: sigmoid, Layers: 3, Neurons: 30, LR: 0.001, Epochs: 50\n",
      "Test Accuracy: 0.9736841917037964, Test Loss: 0.09393240511417389\n",
      "Activation: sigmoid, Layers: 3, Neurons: 30, LR: 0.01, Epochs: 10\n",
      "Test Accuracy: 0.9649122953414917, Test Loss: 0.10383017361164093\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[163], line 29\u001b[0m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, \n\u001b[1;32m     25\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     26\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[1;32m     32\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test_std, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Projects/python_projects/myenv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Projects/python_projects/myenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:345\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[1;32m    336\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m    337\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    343\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    344\u001b[0m     )\n\u001b[0;32m--> 345\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    357\u001b[0m }\n\u001b[1;32m    358\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/Documents/Projects/python_projects/myenv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Projects/python_projects/myenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:431\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m--> 431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menumerate_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_test_batch_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/python_projects/myenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:689\u001b[0m, in \u001b[0;36mTFEpochIterator.enumerate_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_iterator\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 689\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches:\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\n\u001b[1;32m    692\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution\n\u001b[1;32m    693\u001b[0m         ):\n",
      "File \u001b[0;32m~/Documents/Projects/python_projects/myenv/lib/python3.12/site-packages/tensorflow/python/data/ops/dataset_ops.py:501\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[1;32m    500\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Projects/python_projects/myenv/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:709\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    705\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 709\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Projects/python_projects/myenv/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:748\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    746\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[1;32m    747\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[0;32m--> 748\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/python_projects/myenv/lib/python3.12/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3478\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3477\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3478\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3479\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3481\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Iterate through different parameter combinations\n",
    "for activation in activation_functions:\n",
    "    for num_layers in hidden_layers_range:\n",
    "        for neurons in neurons_range:\n",
    "            for lr in learning_rates:\n",
    "                for epochs in epochs_range:\n",
    "                    \n",
    "                    # Create the model\n",
    "                    model = tf.Module()\n",
    "                    layers = [tf.keras.layers.InputLayer(input_shape=(input_shape,))]\n",
    "                    \n",
    "                    # Add hidden layers\n",
    "                    for _ in range(num_layers):\n",
    "                        layers.append(tf.keras.layers.Dense(neurons, activation=activation))\n",
    "                    \n",
    "                    # Output layer\n",
    "                    layers.append(tf.keras.layers.Dense(2, activation='sigmoid'))\n",
    "                    \n",
    "                    # Build the model\n",
    "                    model = tf.keras.Sequential(layers)\n",
    "                    \n",
    "                    # Compile the model with varying learning rates\n",
    "                    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "                    model.compile(optimizer=optimizer, \n",
    "                                  loss='sparse_categorical_crossentropy', \n",
    "                                  metrics=['accuracy'])\n",
    "                    \n",
    "                    # Train the model\n",
    "                    history = model.fit(X_train_std, y_train, validation_split=0.1, epochs=epochs, verbose=0)\n",
    "                    \n",
    "                    # Evaluate the model on the test set\n",
    "                    test_loss, test_acc = model.evaluate(X_test_std, y_test, verbose=0)\n",
    "                    \n",
    "                    # Store results in matrix\n",
    "                    performance_matrix.append({\n",
    "                        'activation': activation,\n",
    "                        'layers': num_layers,\n",
    "                        'neurons': neurons,\n",
    "                        'learning_rate': lr,\n",
    "                        'epochs': epochs,\n",
    "                        'train_accuracy': history.history['accuracy'][-1],\n",
    "                        'val_accuracy': history.history['val_accuracy'][-1],\n",
    "                        'test_accuracy': test_acc,\n",
    "                        'test_loss': test_loss\n",
    "                    })\n",
    "                    \n",
    "                    # Print progress\n",
    "                    print(f\"Activation: {activation}, Layers: {num_layers}, Neurons: {neurons}, LR: {lr}, Epochs: {epochs}\")\n",
    "                    print(f\"Test Accuracy: {test_acc}, Test Loss: {test_loss}\")\n",
    "\n",
    "# Convert performance matrix to DataFrame for better analysis\n",
    "performance_df = pd.DataFrame(performance_matrix)\n",
    "\n",
    "# Display the top 5 best performing models\n",
    "print(performance_df.sort_values(by='test_accuracy', ascending=False).head())\n",
    "\n",
    "# Plot the performance of each model\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot Accuracy vs Epochs for each model\n",
    "for index, row in performance_df.iterrows():\n",
    "    plt.plot(range(row['epochs']), row['train_accuracy'], label=f\"{row['activation']}, Layers: {row['layers']}, Neurons: {row['neurons']}, LR: {row['learning_rate']}\")\n",
    "    \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Training Accuracy over Epochs')\n",
    "plt.legend(loc='best', bbox_to_anchor=(1, 1))\n",
    "plt.show()\n",
    "\n",
    "# Show model performance matrix\n",
    "print(performance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the layers of Neural Network\n",
    "\n",
    "model = keras.Sequential([\n",
    "                          keras.layers.Flatten(input_shape=(30,)),\n",
    "                          keras.layers.Dense(20, activation='relu'),\n",
    "                          keras.layers.Dense(2, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the Neural Network\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the Meural Network\n",
    "\n",
    "history = model.fit(X_train_std, y_train, validation_split=0.1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(['training data', 'validation data'], loc = 'lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(['training data', 'validation data'], loc = 'upper right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
